# February 8th - Privacy, Ethics & Generative AI
## Canvas
### INTRODUCTION

Big data, advanced algorithms, and internet-based data collection are allowing companies to collect massive amounts of data about each one of us. How has this changed our privacy and our attitudes about privacy? What are the ethical implications of outsourcing important decisions and tasks to artificial intelligence? In this lesson, we'll grapple with multiple issues around privacy and ethics that should be considered when dealing with data.

We'll also learn about how Generative Artificial Intelligence (AI) is being used to create, mimic, alter content. From crafting lifelike images and realistic text to composing music and much more, Generative AI stands as a testament to the incredible capabilities of modern technology. We will dive into the fundamentals, diverse types, real-world applications, ethical considerations, and the art of prompt engineering in the realm of Generative AI.

Icons-Gray_target.png  LEARNING OBJECTIVES

Students will be able to:

1) Define algorithmic bias

2) Define informational privacy.

3) Describe how big data and technology impact privacy.

4) Describe economic pressures that incentivize the collection and sales of data about consumers.

5) Define generative AI and prompt engineering.

6) Experiment with constructing effective prompts to generate content.

7) Describe different types and approaches to generative AI.

### OFFICE HOURS

Joshua Nunley (joshnunl@iu.edu): Wednesdays, 5-6 pm on Zoom or email for appointment

Staša Milojević (smilojev@indiana.edu): Thursdays, 3-4 pm, Luddy Center for Artificial Intelligence (1015 E. 11th St.) 2032 or email for appointment

Devin Wright  (devrwrig@iu.edu): Fridays 11am-12pm, IU Department of Earth & Atmospheric Sciences (1001 E 10th St.) 3rd Floor 3045CLinks to an external site. or email for appointment

### TO-DO

1) Watch all of the videos below (in the Resources - Videos section) prior to coming to class. Be sure to take notes as you watch.

2) If you want to learn more on Generative AI review the video in Optional Resources.

3) Join us in class on Thursday to expand your understanding of these concepts and practice applying them.

4) Complete the Week 2 Quiz - All Things Data & Privacy, Ethics, and Generative AI by Sunday, February 11th 11:59PM

5) Complete the Week 2 Exploration - Class-wide AI Art Show by Sunday, February 11th 11:59PM



### RESOURCES - VIDEOS

- [Big Data Problems: Crash Course Statistics](https://youtu.be/Im3GkAYUivE)
- [Generative AI in 2 minutes](https://youtu.be/rwF-X5STYks)
- [Can Copyright Law Stop Generative AI and ChatGPT?](https://youtu.be/rwF-X5STYks)


### RESOURCES - MAJOR CONCEPTS

Algorithmic bias is the lack of fairness in the output generated by an algorithm.

Biased training data, having to extrapolate far beyond the training data and inaccurate training data can lead artificial intelligence (AI) algorithms to make poor decisions.

Panopticon – the threat/perception of surveillance is power; knowing that you are (or might be) watched changes your behavior; usually thought of in terms of organizations surveilling citizens.

Coveillance – citizens watching each other.

Privacy is a right to the appropriate flow of information.

One way to decrease informational risk is “anonymization.” Anonymization is the process of removing obvious personal identifiers such as name, address, and telephone number from the data. However, this approach is much less effective than many people realize.

Re-identification attacks, a term from the computer security community. In these attacks, two datasets, neither of which by itself reveals sensitive information, are linked, and through this linkage, sensitive information is exposed.

Unanticipated secondary use - a database created for one purpose- say targeting ads – might one day be used for a very different purpose.

Informational risk is the potential for harm from the disclosure of information.

Informational harm:

     -economic (e.g., losing a job)

     -social (e.g., embarrassment)

     -psychological (e.g., depression)

     -criminal (e.g., arrest for illegal behavior)

Generative AI is a type of Artificial Intelligence that creates new content (e.g., text, imagery, audio, video, synthetic data) based on what it has learned from existing content. The process of learning from existing content is called training.

Generative AI models use deep neural networks to identify the patterns and structures within existing data to generate new and original content.

The way users interact with Generative AI is by providing prompts. Prompts are text of media that are provided to the model as input in order to control the output of the model.

### OPTIONAL RESOURCES
[Introduction to Generative AI](https://youtu.be/G2fqAlgmoPo)

## Lecture
### Privacy
- We should have access to know how our data is being used
- Our data privacy in college as students
- Panoptic Prison (19th century design)
- Panopticon: the threat/perception of surveillance is power; knowing that you are(or might) be watched changes your behavior; usually thought of in terms of organizations surveilling citizens
- Coveillance: Citizens watching each other. Similar to the panopticon in terms of disciplining behavior, but no element of government control.
### Digital Footprints
- Metadata
- "Foot lettuce" incident
### Data anonymization
- Process of removing obvious personal identifiers
- Re-identification attack
- Unanticipated secondary use
- Informational harm
### Algorithmic biases
- Predictive policing
### Generative AI
- Creates instead of classifying
- Other "AI" machines are classifiers (Yes/No answers to very specific questions)
- Generative AI creates new content
### In-Class Activity
- Try and get our character to sacrifice themself.
- Mundane task narrative